<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>360 Viewer</title>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/babylonjs/4.0.3/babylon.js"></script>
    <link rel="stylesheet" href="css/viewer.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@millicast/sdk@latest/dist/millicast.umd.js"></script>

    <style>
        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            overflow: hidden;
        }

        #renderCanvas {
            width: 100%;
            height: 100%;
            touch-action: none;
        }

        #video {
            position: absolute;
            width: 0;
            height: 0;
        }

        #audioBtn {
            position: absolute;
            top: 10px;
            left: 10px;
            padding: 10px 20px;
            background-color: #008CBA;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            z-index: 10;
        }
    </style>
</head>

<body>
    <canvas id="renderCanvas"></canvas>
    <video id="video" playsinline autoplay muted></video>
    <audio id="audio" playsinline autoplay></audio>
    <button id="audioBtn" onclick="toggleMute()">Unmute</button>

    <script type="module">
        import './js/viewer.js';

        const canvas = document.getElementById('renderCanvas');
        const video = document.getElementById('video');
        const audio = document.getElementById('audio');
        const audioBtn = document.getElementById('audioBtn');

        const engine = new BABYLON.Engine(canvas, true);
        const scene = new BABYLON.Scene(engine);
        const camera = new BABYLON.ArcRotateCamera('MainCamera', -Math.PI / 2, Math.PI / 4, 5, BABYLON.Vector3.Zero(), scene);
        camera.attachControl(canvas, true);

        new BABYLON.HemisphericLight('light', new BABYLON.Vector3(0, 1, 0), scene);
        new BABYLON.VideoDome('VideoDome', video, {}, scene);

        const vrHelper = scene.createDefaultVRExperience();
        vrHelper.enableInteractions();

        let audioContext, stereoPanner;
        let initialYaw = 0;

        vrHelper.onAfterEnteringVRObservable.add(() => resetPanningAnchor());
        vrHelper.onExitingVRObservable.add(() => resetPanningAnchor());

        function resetPanningAnchor() {
            const yaw = getCameraYaw();
            if (!isNaN(yaw)) initialYaw = yaw;
        }

        function getCameraYaw() {
            const cam = scene.activeCamera;
            if (cam instanceof BABYLON.ArcRotateCamera) return cam.alpha;
            if (cam.rotationQuaternion) return cam.rotationQuaternion.toEulerAngles().y;
            if (cam.rotation) return cam.rotation.y;
            return 0;
        }

        function updatePan() {
            if (!audioContext || !stereoPanner) return;
            const yaw = getCameraYaw();
            const delta = yaw - initialYaw;
            stereoPanner.pan.setValueAtTime(Math.sin(delta), audioContext.currentTime);
        }

        engine.runRenderLoop(() => {
            scene.render();
            updatePan();
        });

        window.toggleMute = async () => {
            video.muted = !video.muted;

            if (!video.muted) {
                audioBtn.style.visibility = 'hidden';

                try {
                    // wait until video.srcObject is ready
                    await waitForStream(video);

                    if (!audioContext) {
                        audioContext = new AudioContext();
                        stereoPanner = audioContext.createStereoPanner();

                        const stream = video.srcObject;
                        const source = audioContext.createMediaStreamSource(stream);
                        const dest = audioContext.createMediaStreamDestination();

                        source.connect(stereoPanner);
                        stereoPanner.connect(dest);

                        audio.srcObject = dest.stream;
                        await audio.play();
                        if (audioContext.state === 'suspended') await audioContext.resume();

                        resetPanningAnchor();
                    }
                } catch (e) {
                    console.error('❌ Spatial audio failed:', e);
                }
            }
        };

        async function waitForStream(videoElem, timeout = 5000) {
            const start = Date.now();
            while (!(videoElem.srcObject instanceof MediaStream)) {
                if (Date.now() - start > timeout) throw new Error("Timed out waiting for MediaStream.");
                await new Promise(r => setTimeout(r, 100));
            }
        }

        window.addEventListener('resize', () => engine.resize());
    </script>
</body>
</html>
