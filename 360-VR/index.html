<!DOCTYPE html>
<html >

<head>
    <meta charset="UTF-8">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/babylonjs/4.0.3/babylon.js"></script>
<link type="text/css" rel="stylesheet" href="css/viewer.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
 <script src='https://cdn.jsdelivr.net/npm/@millicast/sdk@latest/dist/millicast.umd.js'></script>


    <style>
        html,
        body {
            overflow: hidden;
            width: 100%;

            height: 100%;
            margin: 0;
            padding: 0;
        }

        #renderCanvas {
            width: 100%;
            height: 100%;
            touch-action: none;
        }
    </style>
</head>
<body>
    <canvas id="renderCanvas"></canvas>
    <video id="video" disablePictureInPicture controlsList="nodownload" playsinline controls autoplay muted  ></video>
     <button id="audioBtn" class="btn-audio"  onClick="toggleMute()" type="button"></button>
     <script src="js/viewer.js"></script>
<script>

              window.AudioContext = window.AudioContext || window.webkitAudioContext;
             // Set up an audio element to feed the ambisonic source audio feed.
              const audioElement = document.createElement('video');
              const audioContext = new AudioContext();
       
              if (window.MediaSource) {
              var mediaSource = new MediaSource();
               } else {
              console.log('The Media Source Extensions API is not supported.');
              }
             //BabylonJS need new audio source 
             const audioElementSource = audioContext.createMediaElementSource(audioElement);
             const canvas = document.getElementById('renderCanvas');
             const engine = new BABYLON.Engine(canvas, true);

             const createScene = function (videoElem) {
             const scene = new BABYLON.Scene(engine);

            // https://babylonjsguide.github.io/basics/Cameras#arc-rotate-camera
            const camera = new BABYLON.ArcRotateCamera('MainCamera', -1, 0, 1, new BABYLON.Vector3(0, 0, 0), scene);

            camera.setTarget(BABYLON.Vector3.Zero());
            camera.attachControl(canvas, true);

            const light = new BABYLON.HemisphericLight('Light', new BABYLON.Vector3(0, 0, 0), scene);

            const videoDome = new BABYLON.VideoDome(
                'VideoDome',
                videoElem,
                {},
                scene
             );

            return scene;
       
          };

         var videoElem = document.getElementById('video');
         const scene = createScene(videoElem);
         const playPauseVideoDome = () => {
         const videoDome = scene.getNodeByName('VideoDome');
         const video = videoDome.videoTexture.video;
         video.paused ? video.play() : video.pause();
         renderer.setRotationMatrix4(camera.scene);
         alert(renderer.setRotationMatrix4);

          }
       scene.onKeyboardObservable.add(e => {
            switch (e.event.type) {
                case 'keydown':
                    if (e.event.key === ' ') {
                        playPauseVideoDome();
                    }
                    break;
            }
        })

        const vrHelper = scene.createDefaultVRExperience();
        vrHelper.enableInteractions();

           vrHelper.onControllerMeshLoaded.add((webVRController) => {
            var controllerMesh = webVRController.mesh;
            webVRController.onTriggerStateChangedObservable.add(() => {
              playPauseVideoDome();
            });
        });     

        engine.runRenderLoop(() => {
            scene.render();
                });
    
        window.addEventListener('resize', function () {
            engine.resize();
     
        });

        const playVideoDome = () => {
            const videoDome = scene.getNodeByName('VideoDome')
            videoDome.videoTexture.video.play()
           renderer.setRotationMatrix4(scene.videoDome); 
        }

        var box = BABYLON.Mesh.CreateBox("create", 2, scene);
        box.material = new BABYLON.StandardMaterial("Mat", scene);
        //box.material.diffuseTexture = new BABYLON.Texture("textures/crate.png", scene);
        box.position = new BABYLON.Vector3(0, 1, 0);

       //audioContext needs to be a valid wave or MP3 source to attach
         var audioStream = new BABYLON.Sound("Live", audioContext.ogg, scene, null, {
        //MESH WILL WORK IF MP3 or Wav Comment above and uncomment below for example
        //var audioStream = new BABYLON.Sound("ColdPlay", "https://nerdits.com/audio/asfos.mp3", scene, null, {
        spatialSound: true,
        streaming: true,
        loop: true,
        autoplay: true,
        useCustomAttenuation: true
        });
       // Sound will now follow the box mesh position
       audioStream.setDirectionalCone(90, 180, 0);
       audioStream.setLocalDirectionToMesh(new BABYLON.Vector3(1, 0, 0));

       audioStream.attachToMesh(box);
</script>
</body>
</html>
